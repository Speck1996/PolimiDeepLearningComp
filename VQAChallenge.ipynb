{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcUFngo0HSp5"
      },
      "source": [
        "# Visual Question Answering Challenge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCN3fYK2pvh5"
      },
      "source": [
        "## Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFUN8YAhDJ_f",
        "trusted": true,
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "!python -m spacy download en_vectors_web_lg\n",
        "!pip install -U spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9Sliwr7pFSK",
        "trusted": true,
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "import sys, warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from random import shuffle, sample\n",
        "import pickle as pk\n",
        "import gc\n",
        "import tensorflow as tf\n",
        "import json\n",
        "import os\n",
        "from datetime import datetime\n",
        "from collections import defaultdict\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.io\n",
        "import spacy\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Reshape\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.keras.layers import Concatenate\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUlhKnak-b8Y",
        "trusted": true,
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Set the seed for random operations.\n",
        "# This let our experiments to be reproducible.\n",
        "SEED = 4242\n",
        "tf.random.set_seed(SEED)\n",
        "np.random.seed(4242)\n",
        "random.seed(SEED)\n",
        "\n",
        "# Set GPU memory growth\n",
        "# Allows to only as much GPU memory as needed\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        # Currently, memory growth needs to be the same across GPUs\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "    except RuntimeError as e:\n",
        "        # Memory growth must be set before GPUs have been initialized\n",
        "        print(e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csQlteOhpHDB"
      },
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-QaHj7N2EW6",
        "trusted": true,
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "### Parameters ###\n",
        "\n",
        "# Number of classes\n",
        "num_classes = 13\n",
        "\n",
        "# Json path and keys\n",
        "cwd = os.getcwd()\n",
        "DATASET_PATH = os.path.join(cwd, 'dataset_vqa')\n",
        "TRAIN_IMG_PATH = os.path.join(INPUT_PATH, 'train')\n",
        "TEST_IMG_PATH = os.path.join(INPUT_PATH, 'test')\n",
        "TRAIN_JSON_PATH = os.path.join(INPUT_PATH, 'train_data.json')\n",
        "TEST_JSON_PATH = os.path.join(INPUT_PATH, 'test_data.json')\n",
        "\n",
        "QUESTION_KEY = 'question'\n",
        "ANSWER_KEY = 'answer'\n",
        "IMAGE_KEY = 'image_filename'\n",
        "\n",
        "# Split ratio\n",
        "train_split = 0.8\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utPU57misKJc",
        "trusted": true,
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "decide_class_indices = True\n",
        "\n",
        "if decide_class_indices:\n",
        "    classes = [\n",
        "        '0',  # 0\n",
        "        '1',  # 1\n",
        "        '2',  # 2\n",
        "        '3',  # 3\n",
        "        '4',  # 4\n",
        "        '5',  # 5\n",
        "        '6',  # 6\n",
        "        '7',  # 7\n",
        "        '8',  # 8\n",
        "        '9',  # 9\n",
        "        '10',  # 10\n",
        "        'yes',  # 11\n",
        "        'no'  # 12\n",
        "    ]\n",
        "else:\n",
        "    classes = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jk-BntHcsUKM",
        "trusted": true,
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Opening json\n",
        "with open(TRAIN_JSON_PATH, 'r') as f:\n",
        "    SUBSET_data = json.load(f)\n",
        "f.close()\n",
        "\n",
        "\n",
        "# Splitting the question\n",
        "questions = SUBSET_data.get(\"questions\")\n",
        "\n",
        "# This will be needed later for our vocabulary\n",
        "whole_text = []\n",
        "for question in questions:\n",
        "    question_text = question.get(QUESTION_KEY)\n",
        "    whole_text.append(question_text)\n",
        "\n",
        "random.shuffle(questions)\n",
        "split_index = int(train_split * len(questions))\n",
        "\n",
        "# Getting the list of questions\n",
        "train_questions = questions[:split_index]\n",
        "valid_questions = questions[split_index:]\n",
        "\n",
        "# Checking that all the questions are inside in the two sets\n",
        "assert len(train_questions) + len(valid_questions) == len(questions)\n",
        "\n",
        "# Checking that all the questions are successfully imported\n",
        "assert len(questions) == 259492\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKnHC67RybIw",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Generating the embedding matrix through GloVe encoding\n",
        "# Getting all the tokens\n",
        "token = Tokenizer()\n",
        "token.fit_on_texts(whole_text)\n",
        "seq = token.texts_to_sequences(whole_text)\n",
        "\n",
        "# The matrix needs fixed lenght sequences (300 is a standard value\n",
        "# for GloVe coefficients)\n",
        "pad_seq = pad_sequences(seq, maxlen=300)\n",
        "\n",
        "# the additional unit is for unkwown words, needed in the embedding\n",
        "# layer for our RNN\n",
        "vocab_size = len(token.word_index)+1\n",
        "print(\"vocab size \" + vocab_size)\n",
        "\n",
        "# This object contains a series of utilities for\n",
        "# nlp, it will come in handy when it will be time to\n",
        "# convert words into GloVe coefficients\n",
        "nlp = spacy.load('en_vectors_web_lg')\n",
        "\n",
        "print(\"starting the embedding\")\n",
        "# Our beloved matrix\n",
        "embedding_matrix = np.zeros((vocab_size, 300))\n",
        "for word, i in tqdm(token.word_index.items()):\n",
        "    embedding_coeff = nlp.vocab[word].vector\n",
        "    if embedding_coeff is not None:\n",
        "        embedding_array = np.array(embedding_coeff, dtype='float32')\n",
        "        embedding_matrix[i] = embedding_array\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7pyb4fZJ_joQ",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from keras.utils import np_utils\n",
        "\n",
        "\n",
        "def preprocess_qst(question):\n",
        "\n",
        "    question_tokens = token.texts_to_sequences(question)\n",
        "    question_seq = pad_sequences(question_tokens, maxlen=300)\n",
        "\n",
        "    return (question_seq)\n",
        "\n",
        "\n",
        "def preprocess_answ(answer):\n",
        "\n",
        "    index = classes.index(answer)\n",
        "    index = np.array(index)\n",
        "    encoded_answ = np_utils.to_categorical(index, num_classes)\n",
        "\n",
        "    return (encoded_answ)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oe3KWCJV1wO2",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from skimage.io import imread\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "# takes as input the question, returns corresponding image\n",
        "\n",
        "\n",
        "def get_img(question, base_path):\n",
        "\n",
        "    img_name = question.get(IMAGE_KEY)\n",
        "    img_path = os.path.join(base_path, img_name)\n",
        "    img = imread(img_path)\n",
        "\n",
        "    return(img)\n",
        "\n",
        "# preprocessing of the image\n",
        "\n",
        "\n",
        "def preprocess_img(img, data_aug=False):\n",
        "\n",
        "    # Resizing and rescaling the image\n",
        "    img_array = np.array(img)\n",
        "    img_array = preprocess_input(img_array)\n",
        "\n",
        "    return(img_array)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BR-OU9Yd3S-a",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# generator used to create batch of images/questions and corresponding answers\n",
        "\n",
        "def data_generator(questions, batch_size=bs, data_aug=False):\n",
        "\n",
        "    while True:\n",
        "\n",
        "        # Select questions for the batch\n",
        "        batch_questions = np.random.choice(a=questions,\n",
        "                                           size=batch_size)\n",
        "        batch_input = []\n",
        "        batch_output = []\n",
        "\n",
        "        # Read in each input, perform preprocessing and get labels\n",
        "        for question in questions:\n",
        "\n",
        "            # Recovering the image through the corresponding image name in\n",
        "            # the question.\n",
        "            # This will be our X_img, X_question set\n",
        "\n",
        "            img = get_img(question, TRAIN_IMG_PATH)\n",
        "\n",
        "            # Image preprocessing\n",
        "            img_array = preprocess_img(img, data_aug=data_aug)\n",
        "\n",
        "            # Question text preprocessing\n",
        "            question_text = question.get(QUESTION_KEY)\n",
        "            question_array = preprocess_qst(question_text)\n",
        "\n",
        "            input = [img_array, question_array]\n",
        "\n",
        "            # The expected output is the corresponding answer to the question\n",
        "            answer_str = question.get(ANSWER_KEY)\n",
        "            output = preprocess_answ(answer_str)\n",
        "\n",
        "            batch_input += [input]\n",
        "            batch_output += [output]\n",
        "\n",
        "        # Return a tuple of (input,output) to feed the network\n",
        "        batch_x = np.array(batch_input)\n",
        "        batch_y = np.array(batch_output)\n",
        "\n",
        "        yield(batch_x, batch_y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxY0hW4Sq-_q"
      },
      "source": [
        "## Building the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tIcHC6ceqNAX",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "######################## Network Parameters ####################################\n",
        "bs = 8\n",
        "img_dim = 4096\n",
        "word2vec_dim = 300\n",
        "\n",
        "######################## Training Parameters ####################################\n",
        "num_epochs = 300\n",
        "loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "lr = 1e-3\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "metrics = ['accuracy']\n",
        "\n",
        "# Others\n",
        "img_w = 224\n",
        "img_h = 224\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dt8AZSk4sNSb",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Image Model (VGG).... The last two layers are popped so later the\n",
        "# the network can be combined with the language related one\n",
        "vgg16_model = tf.keras.applications.VGG16(\n",
        "    weights='imagenet', include_top=True, input_shape=(img_h, img_w, 3))\n",
        "vgg16_model.summary()\n",
        "\n",
        "image_model = Sequential()\n",
        "for layer in vgg16_model.layers[:-2]:  # just exclude last layer from copying\n",
        "    image_model.add(layer)\n",
        "\n",
        "image_model.add(Dense(2048, activation='sigmoid'))\n",
        "image_model.add(Dense(1024, activation='sigmoid'))\n",
        "image_model.summary()\n",
        "\n",
        "# Language Model (LSTM)\n",
        "question_input = tf.keras.layers.Embedding(vocab_size, 300, weights=[embedding_matrix],\n",
        "                                           input_length=300, trainable=False)\n",
        "\n",
        "language_model = Sequential()\n",
        "language_model.add(question_input)\n",
        "language_model.add(LSTM(1024))\n",
        "\n",
        "language_model.summary()\n",
        "\n",
        "# VQA model = CNN + RNN (LSTM)\n",
        "mult = tf.keras.layers.Multiply()([image_model.output, language_model.output])\n",
        "x = Dropout(0.2)(mult)\n",
        "x = Dense(512, activation='sigmoid')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "out = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "vqa_model = tf.keras.models.Model(\n",
        "    [image_model.input, language_model.input], out)\n",
        "vqa_model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhQuDvNGA3HA",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "vqa_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyO3Ebgp7lHH"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqmpkSTE4lm9",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "exps_dir = os.path.join(cwd, 'classification_experiments')\n",
        "if not os.path.exists(exps_dir):\n",
        "    os.makedirs(exps_dir)\n",
        "\n",
        "now = datetime.now().strftime('%b%d_%H-%M-%S')\n",
        "\n",
        "model_name = 'CNN'\n",
        "\n",
        "exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n",
        "if not os.path.exists(exp_dir):\n",
        "    os.makedirs(exp_dir)\n",
        "\n",
        "callbacks = []\n",
        "\n",
        "# Model checkpoint\n",
        "# ----------------\n",
        "ckpt_dir = os.path.join(exp_dir, 'ckpts')\n",
        "if not os.path.exists(ckpt_dir):\n",
        "    os.makedirs(ckpt_dir)\n",
        "\n",
        "# ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp_{epoch:02d}.ckpt'),\n",
        "#                                                   save_weights_only=True)  # False to save the model directly\n",
        "# callbacks.append(ckpt_callback)\n",
        "\n",
        "# Visualize Learning on Tensorboard\n",
        "# ---------------------------------\n",
        "tb_dir = os.path.join(exp_dir, 'tb_logs')\n",
        "if not os.path.exists(tb_dir):\n",
        "    os.makedirs(tb_dir)\n",
        "    print(tb_dir)\n",
        "\n",
        "# By default shows losses and metrics for both training and validation\n",
        "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n",
        "                                             profile_batch=0,\n",
        "                                             histogram_freq=1)  # if 1 shows weights histograms\n",
        "callbacks.append(tb_callback)\n",
        "\n",
        "\n",
        "# Early Stopping\n",
        "# --------------\n",
        "early_stop = True\n",
        "if early_stop:\n",
        "    es_callback = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss', patience=10)\n",
        "    callbacks.append(es_callback)\n",
        "\n",
        "\n",
        "vqa_model.fit(generator=data_generator(train_questions),\n",
        "              epochs=num_epochs,\n",
        "              steps_per_epoch=len(train_questions)//bs,\n",
        "              validation_steps=len(valid_questions)//bs,\n",
        "              callbacks=callbacks,\n",
        "              validation_data=data_generator(valid_questions))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Eo-M-K68tt_"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHxe4kE78jCQ",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "def create_csv(results, results_dir='./'):\n",
        "\n",
        "    csv_fname = 'results_'\n",
        "    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n",
        "\n",
        "    with open(os.path.join(results_dir, csv_fname), 'w') as f:\n",
        "\n",
        "        f.write('Id,Category\\n')\n",
        "\n",
        "        for key, value in results.items():\n",
        "            f.write(str(key) + ',' + str(value) + '\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgytBqBw9Em8",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "with open(TEST_JSON_PATH, 'r') as f:\n",
        "    SUBSET_test = json.load(f)\n",
        "f.close()\n",
        "\n",
        "test_questions = SUBSET_test.get('questions')\n",
        "\n",
        "results = {}\n",
        "for question in test_questions:\n",
        "\n",
        "    img = get_img(question, TEST_IMG_PATH)\n",
        "\n",
        "    # Image preprocessing\n",
        "    img_array = preprocess_img(img)\n",
        "\n",
        "    # Question text preprocessing\n",
        "    question_id = question.get(ID)\n",
        "    question_text = question.get(QUESTION)\n",
        "    question_array = preprocess_qst(question)\n",
        "\n",
        "    x_test = [img_array, question_array]\n",
        "\n",
        "    prediction = np.argmax(model.predict(x=x_test))\n",
        "    results[question_id] = prediction\n",
        "\n",
        "print(\"CSV done!\")\n",
        "create_csv(results)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "name": "vqa-challenge.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}